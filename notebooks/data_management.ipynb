{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thuynh/anaconda3/envs/ms-thesis/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data & Annotations Management\n",
    "\n",
    "The following notebook is used to manage the [SUN Dataset](http://sundatabase.org/) data and annotations. \n",
    "\n",
    "## Requirements\n",
    "\n",
    "In order to use this, you need:\n",
    "* Positive cases bounding box annotations. These are contained in the `.txt` files in the [`01_raw/annotation_txt`](../data/01_raw/annotation_txt/) folder for each positive case.\n",
    "* Positive cases polyp pathological diagnosis. The above `.txt` files do not contain information regarding the specific polyp pathological diagnoses, which instead are contained in [`02_intermediate/positive_cases_description.txt`](../data/02_intermediate/positive_cases_description.txt).\n",
    "* An annotation template of your choice to save each **image**'s annotation (the `txt` files are one per positive case). We will use a custom template, somewhat similar to the COCO Annotation template. You can find it in the [`annotation_template.json` template](../data/02_intermediate/annotation_template.json).\n",
    "* A list of the possible polyp pathological diagnoses present in the SUN Dataset. Each polyp class will be associated with a specific ID and a color for visualization purposes. You can find it in the [`02_intermediate/polyp_classes.json` file](../data/02_intermediate/polyp_classes.json).\n",
    "* A list of the cases the negative frames in the SUN Dataset come from. You can find it in the [`02_intermediate/negative_cases_description.txt` file](../data/02_intermediate/negative_cases_description.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base working directory\n",
    "BASE_DIR = '/home/thuynh/ms-thesis'\n",
    "\n",
    "# Data folders\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "RAW_DIR = os.path.join(DATA_DIR, \"01_raw\")\n",
    "INTERMEDIATE_DIR = os.path.join(DATA_DIR, \"02_intermediate\")\n",
    "PRIMARY_DIR = os.path.join(DATA_DIR, '03_primary')\n",
    "MODEL_INPUT_DIR = os.path.join(DATA_DIR, '04_model_input')\n",
    "\n",
    "# Required folders/files\n",
    "ANNOTATIONS_DIR = os.path.join(RAW_DIR, \"annotation_txt\") # Raw case-by-case annotations folder\n",
    "ANNOTATION_TEMPLATE = os.path.join(INTERMEDIATE_DIR, 'annotation_template.json') # Custom annotation template\n",
    "POLYP_CLASSES = os.path.join(INTERMEDIATE_DIR, 'polyp_classes.json') # SUN dataset polyp classes \n",
    "POSITIVE_CASES_DESCRIPTION = os.path.join(INTERMEDIATE_DIR, 'positive_cases_description.txt') # Polyp classes case-by-case\n",
    "NEGATIVE_CASES_DESCRIPTION = os.path.join(INTERMEDIATE_DIR, 'negative_cases_description.txt') # Negative frames and cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "In the `annotation_txt` folder we have the bounding box annotations for each case. However, these annotations are lacking the information on the specific polyp pathological diagnosis. We need to complement that information with the one coming from `positive_cases_description.txt` and `negative_cases_description`. For each case, we only have one polyp diagnosis. \n",
    "\n",
    "What we will do is:\n",
    "#### 1. Read each case annotation file (in `annotation_txt`) and save all cases' annotations in a `pd.DataFrame`.\n",
    "#### 2. Complement each case annotation with information on the specific polyp pathological diagnosis/class (from `positive_cases_description.txt`).\n",
    "#### 3. Add negative images information and class (from `negative_cases_description.txt`). \n",
    "#### 4. Save a separate annotation file for each image (following the `annotation_template.json` template structure) in `03_primary/labels` (negative images too).\n",
    "#### 5. Extract and move all images (positive and negative) to `03_primary/images`.\n",
    "#### 6. Split and save training and validation sets in `04_model_input/train` and `04_model_input/val`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read bounding box annotations\n",
    "\n",
    "**N.B.**: cases #58 and #97 have multiple bbox coordinates for certain images. We selected only one out of the ones specified, based on the coordinates of the bounding box in the images before and after the images with multiple bbox coordinates. The original annotation files were saved as `_case58` and `_case97`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading annotations for each case...: 100%|██████████| 100/100 [00:00<00:00, 204.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Frame_Class</th>\n",
       "      <th>XYXY</th>\n",
       "      <th>ID</th>\n",
       "      <th>XYWH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[408, 545, 568, 722]</td>\n",
       "      <td>1</td>\n",
       "      <td>[488.0, 633.5, 160.0, 177.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[388, 549, 561, 729]</td>\n",
       "      <td>1</td>\n",
       "      <td>[474.5, 639.0, 173.0, 180.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[390, 552, 561, 726]</td>\n",
       "      <td>1</td>\n",
       "      <td>[475.5, 639.0, 171.0, 174.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[390, 552, 561, 730]</td>\n",
       "      <td>1</td>\n",
       "      <td>[475.5, 641.0, 171.0, 178.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[389, 558, 557, 748]</td>\n",
       "      <td>1</td>\n",
       "      <td>[473.0, 653.0, 168.0, 190.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49131</th>\n",
       "      <td>case_M_20181106093315_0U62372110682814_1_007_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[540, 562, 728, 750]</td>\n",
       "      <td>100</td>\n",
       "      <td>[634.0, 656.0, 188.0, 188.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49132</th>\n",
       "      <td>case_M_20181106093315_0U62372110682814_1_007_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[538, 572, 760, 782]</td>\n",
       "      <td>100</td>\n",
       "      <td>[649.0, 677.0, 222.0, 210.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49133</th>\n",
       "      <td>case_M_20181106093315_0U62372110682814_1_007_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[538, 572, 761, 780]</td>\n",
       "      <td>100</td>\n",
       "      <td>[649.5, 676.0, 223.0, 208.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49134</th>\n",
       "      <td>case_M_20181106093315_0U62372110682814_1_007_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[537, 569, 763, 783]</td>\n",
       "      <td>100</td>\n",
       "      <td>[650.0, 676.0, 226.0, 214.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49135</th>\n",
       "      <td>case_M_20181106093315_0U62372110682814_1_007_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[552, 558, 778, 748]</td>\n",
       "      <td>100</td>\n",
       "      <td>[665.0, 653.0, 226.0, 190.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49136 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Filename  Frame_Class  \\\n",
       "0      case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "1      case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "2      case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "3      case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "4      case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "...                                                  ...          ...   \n",
       "49131  case_M_20181106093315_0U62372110682814_1_007_0...            0   \n",
       "49132  case_M_20181106093315_0U62372110682814_1_007_0...            0   \n",
       "49133  case_M_20181106093315_0U62372110682814_1_007_0...            0   \n",
       "49134  case_M_20181106093315_0U62372110682814_1_007_0...            0   \n",
       "49135  case_M_20181106093315_0U62372110682814_1_007_0...            0   \n",
       "\n",
       "                       XYXY   ID                          XYWH  \n",
       "0      [408, 545, 568, 722]    1  [488.0, 633.5, 160.0, 177.0]  \n",
       "1      [388, 549, 561, 729]    1  [474.5, 639.0, 173.0, 180.0]  \n",
       "2      [390, 552, 561, 726]    1  [475.5, 639.0, 171.0, 174.0]  \n",
       "3      [390, 552, 561, 730]    1  [475.5, 641.0, 171.0, 178.0]  \n",
       "4      [389, 558, 557, 748]    1  [473.0, 653.0, 168.0, 190.0]  \n",
       "...                     ...  ...                           ...  \n",
       "49131  [540, 562, 728, 750]  100  [634.0, 656.0, 188.0, 188.0]  \n",
       "49132  [538, 572, 760, 782]  100  [649.0, 677.0, 222.0, 210.0]  \n",
       "49133  [538, 572, 761, 780]  100  [649.5, 676.0, 223.0, 208.0]  \n",
       "49134  [537, 569, 763, 783]  100  [650.0, 676.0, 226.0, 214.0]  \n",
       "49135  [552, 558, 778, 748]  100  [665.0, 653.0, 226.0, 190.0]  \n",
       "\n",
       "[49136 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Filename', 'Min_X', 'Min_Y', 'Max_X', 'Max_Y', 'Frame_Class']\n",
    "\n",
    "# Extract list of annotations\n",
    "annotation_files = [f for f in os.listdir(ANNOTATIONS_DIR) if f.startswith('case')]\n",
    "annotation_files = sorted(annotation_files, key=lambda x: int(''.join(filter(str.isdigit, x)))) # sort list of files by ascending number\n",
    "\n",
    "# Store annotations case by case separately\n",
    "positive_annotations_dict = {}\n",
    "\n",
    "for idx, annotation in tqdm.tqdm(enumerate(annotation_files), desc='Loading annotations for each case...', total=len(annotation_files)):\n",
    "    with open(os.path.join(ANNOTATIONS_DIR, annotation), 'r') as f:\n",
    "        # Use a regex for the sep argument (filename is space-separated, coordinates are comma-separated)\n",
    "        # When using regex, need to specify the \"python\" engine\n",
    "        positive_annotations_dict[f'case{idx+1}'] = pd.read_csv(f, sep=' |,', names=columns, engine='python')\n",
    "        \n",
    "    # Combine bbox coordinates into a single column\n",
    "    positive_annotations_dict[f'case{idx+1}']['XYXY'] = positive_annotations_dict[f'case{idx+1}'].iloc[:, 1:5].to_numpy().tolist()\n",
    "\n",
    "    # Clean-up\n",
    "    positive_annotations_dict[f'case{idx+1}'].drop(columns=['Min_X', 'Min_Y', 'Max_X', 'Max_Y'], inplace=True)\n",
    "    positive_annotations_dict[f'case{idx+1}']['ID'] = idx+1\n",
    "\n",
    "# Concatenate everything in a single pd.DataFrame\n",
    "positive_annotations = pd.concat([case for case in positive_annotations_dict.values()]).reset_index(drop=True)\n",
    "\n",
    "# Boxes are in XYXY format, we also want XYWH format (aka COCO format).\n",
    "positive_annotations['XYWH'] = positive_annotations['XYXY'].apply(lambda x: torchvision.ops.box_convert(torch.tensor(x), 'xyxy', 'cxcywh').tolist())\n",
    "\n",
    "positive_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Complement annotations with specific polyp diagnoses.\n",
    "\n",
    "The polyp pathological diagnoses were extracted from the SUN Dataset homepage (_Table 2_), and saved in `positive_cases_description.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Size</th>\n",
       "      <th>Location</th>\n",
       "      <th>Pathological_Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Is</td>\n",
       "      <td>6mm</td>\n",
       "      <td>C</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Is</td>\n",
       "      <td>18mm</td>\n",
       "      <td>R</td>\n",
       "      <td>High-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>IIa</td>\n",
       "      <td>3mm</td>\n",
       "      <td>A</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Is</td>\n",
       "      <td>4mm</td>\n",
       "      <td>S</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>IIa</td>\n",
       "      <td>3mm</td>\n",
       "      <td>T</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Is</td>\n",
       "      <td>5mm</td>\n",
       "      <td>S</td>\n",
       "      <td>Hyperplastic polyp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>IIa</td>\n",
       "      <td>15mm-</td>\n",
       "      <td>C</td>\n",
       "      <td>Sessile serrated lesion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>IIa</td>\n",
       "      <td>4mm</td>\n",
       "      <td>T</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Is</td>\n",
       "      <td>5mm</td>\n",
       "      <td>S</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>IIa</td>\n",
       "      <td>3mm</td>\n",
       "      <td>R</td>\n",
       "      <td>Hyperplastic polyp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID Shape   Size Location   Pathological_Diagnosis\n",
       "0     1    Is    6mm        C        Low-grade adenoma\n",
       "1     2    Is   18mm        R       High-grade adenoma\n",
       "2     3   IIa    3mm        A        Low-grade adenoma\n",
       "3     4    Is    4mm        S        Low-grade adenoma\n",
       "4     5   IIa    3mm        T        Low-grade adenoma\n",
       "..  ...   ...    ...      ...                      ...\n",
       "95   96    Is    5mm        S       Hyperplastic polyp\n",
       "96   97   IIa  15mm-        C  Sessile serrated lesion\n",
       "97   98   IIa    4mm        T        Low-grade adenoma\n",
       "98   99    Is    5mm        S        Low-grade adenoma\n",
       "99  100   IIa    3mm        R       Hyperplastic polyp\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read positive cases description file\n",
    "with open(POSITIVE_CASES_DESCRIPTION, 'r') as f:\n",
    "    positive_cases_desc = pd.read_csv(f, sep='\\t', header=0, thousands=',').drop(columns=['Number of frames']).rename(columns={'Pathological diagnosis': 'Pathological_Diagnosis'})\n",
    "\n",
    "positive_cases_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Frame_Class</th>\n",
       "      <th>XYXY</th>\n",
       "      <th>ID</th>\n",
       "      <th>XYWH</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Size</th>\n",
       "      <th>Location</th>\n",
       "      <th>Pathological_Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[408, 545, 568, 722]</td>\n",
       "      <td>1</td>\n",
       "      <td>[488.0, 633.5, 160.0, 177.0]</td>\n",
       "      <td>Is</td>\n",
       "      <td>6mm</td>\n",
       "      <td>C</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[388, 549, 561, 729]</td>\n",
       "      <td>1</td>\n",
       "      <td>[474.5, 639.0, 173.0, 180.0]</td>\n",
       "      <td>Is</td>\n",
       "      <td>6mm</td>\n",
       "      <td>C</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[390, 552, 561, 726]</td>\n",
       "      <td>1</td>\n",
       "      <td>[475.5, 639.0, 171.0, 174.0]</td>\n",
       "      <td>Is</td>\n",
       "      <td>6mm</td>\n",
       "      <td>C</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[390, 552, 561, 730]</td>\n",
       "      <td>1</td>\n",
       "      <td>[475.5, 641.0, 171.0, 178.0]</td>\n",
       "      <td>Is</td>\n",
       "      <td>6mm</td>\n",
       "      <td>C</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[389, 558, 557, 748]</td>\n",
       "      <td>1</td>\n",
       "      <td>[473.0, 653.0, 168.0, 190.0]</td>\n",
       "      <td>Is</td>\n",
       "      <td>6mm</td>\n",
       "      <td>C</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49131</th>\n",
       "      <td>case_M_20181106093315_0U62372110682814_1_007_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[540, 562, 728, 750]</td>\n",
       "      <td>100</td>\n",
       "      <td>[634.0, 656.0, 188.0, 188.0]</td>\n",
       "      <td>IIa</td>\n",
       "      <td>3mm</td>\n",
       "      <td>R</td>\n",
       "      <td>Hyperplastic polyp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49132</th>\n",
       "      <td>case_M_20181106093315_0U62372110682814_1_007_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[538, 572, 760, 782]</td>\n",
       "      <td>100</td>\n",
       "      <td>[649.0, 677.0, 222.0, 210.0]</td>\n",
       "      <td>IIa</td>\n",
       "      <td>3mm</td>\n",
       "      <td>R</td>\n",
       "      <td>Hyperplastic polyp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49133</th>\n",
       "      <td>case_M_20181106093315_0U62372110682814_1_007_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[538, 572, 761, 780]</td>\n",
       "      <td>100</td>\n",
       "      <td>[649.5, 676.0, 223.0, 208.0]</td>\n",
       "      <td>IIa</td>\n",
       "      <td>3mm</td>\n",
       "      <td>R</td>\n",
       "      <td>Hyperplastic polyp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49134</th>\n",
       "      <td>case_M_20181106093315_0U62372110682814_1_007_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[537, 569, 763, 783]</td>\n",
       "      <td>100</td>\n",
       "      <td>[650.0, 676.0, 226.0, 214.0]</td>\n",
       "      <td>IIa</td>\n",
       "      <td>3mm</td>\n",
       "      <td>R</td>\n",
       "      <td>Hyperplastic polyp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49135</th>\n",
       "      <td>case_M_20181106093315_0U62372110682814_1_007_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[552, 558, 778, 748]</td>\n",
       "      <td>100</td>\n",
       "      <td>[665.0, 653.0, 226.0, 190.0]</td>\n",
       "      <td>IIa</td>\n",
       "      <td>3mm</td>\n",
       "      <td>R</td>\n",
       "      <td>Hyperplastic polyp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49136 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Filename  Frame_Class  \\\n",
       "0      case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "1      case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "2      case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "3      case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "4      case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "...                                                  ...          ...   \n",
       "49131  case_M_20181106093315_0U62372110682814_1_007_0...            0   \n",
       "49132  case_M_20181106093315_0U62372110682814_1_007_0...            0   \n",
       "49133  case_M_20181106093315_0U62372110682814_1_007_0...            0   \n",
       "49134  case_M_20181106093315_0U62372110682814_1_007_0...            0   \n",
       "49135  case_M_20181106093315_0U62372110682814_1_007_0...            0   \n",
       "\n",
       "                       XYXY   ID                          XYWH Shape Size  \\\n",
       "0      [408, 545, 568, 722]    1  [488.0, 633.5, 160.0, 177.0]    Is  6mm   \n",
       "1      [388, 549, 561, 729]    1  [474.5, 639.0, 173.0, 180.0]    Is  6mm   \n",
       "2      [390, 552, 561, 726]    1  [475.5, 639.0, 171.0, 174.0]    Is  6mm   \n",
       "3      [390, 552, 561, 730]    1  [475.5, 641.0, 171.0, 178.0]    Is  6mm   \n",
       "4      [389, 558, 557, 748]    1  [473.0, 653.0, 168.0, 190.0]    Is  6mm   \n",
       "...                     ...  ...                           ...   ...  ...   \n",
       "49131  [540, 562, 728, 750]  100  [634.0, 656.0, 188.0, 188.0]   IIa  3mm   \n",
       "49132  [538, 572, 760, 782]  100  [649.0, 677.0, 222.0, 210.0]   IIa  3mm   \n",
       "49133  [538, 572, 761, 780]  100  [649.5, 676.0, 223.0, 208.0]   IIa  3mm   \n",
       "49134  [537, 569, 763, 783]  100  [650.0, 676.0, 226.0, 214.0]   IIa  3mm   \n",
       "49135  [552, 558, 778, 748]  100  [665.0, 653.0, 226.0, 190.0]   IIa  3mm   \n",
       "\n",
       "      Location Pathological_Diagnosis  \n",
       "0            C      Low-grade adenoma  \n",
       "1            C      Low-grade adenoma  \n",
       "2            C      Low-grade adenoma  \n",
       "3            C      Low-grade adenoma  \n",
       "4            C      Low-grade adenoma  \n",
       "...        ...                    ...  \n",
       "49131        R     Hyperplastic polyp  \n",
       "49132        R     Hyperplastic polyp  \n",
       "49133        R     Hyperplastic polyp  \n",
       "49134        R     Hyperplastic polyp  \n",
       "49135        R     Hyperplastic polyp  \n",
       "\n",
       "[49136 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the pathological diagnoses with the rest of the information\n",
    "positive_annotations = positive_annotations.merge(positive_cases_desc, on='ID', how='left')\n",
    "\n",
    "positive_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add also the negative frames information.\n",
    "\n",
    "As stated in [_Misawa et al._](https://www.giejournal.org/article/S0016-5107(20)34655-1/fulltext), a small number of negative images (1024 out of 56668) can help with the training and performances of the object detection models. Therefore, we add to our database also the negative frames and possibly experiment with different numbers of negative frames included in the training/validation sets. \n",
    "\n",
    "The information for the negative frames was extracted from the SUN Dataset homepage (_Table 3_), and saved in `negative_cases_description.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Number of frames</th>\n",
       "      <th>Lenth of each video (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9961</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10073</td>\n",
       "      <td>335.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7152</td>\n",
       "      <td>238.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>14635</td>\n",
       "      <td>487.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7916</td>\n",
       "      <td>263.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>17046</td>\n",
       "      <td>511.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5636</td>\n",
       "      <td>169.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2568</td>\n",
       "      <td>85.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>9522</td>\n",
       "      <td>317.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>7086</td>\n",
       "      <td>236.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>4832</td>\n",
       "      <td>161.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>6799</td>\n",
       "      <td>226.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>6328</td>\n",
       "      <td>210.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  Number of frames  Lenth of each video (seconds)\n",
       "0    1              9961                          332.0\n",
       "1    2             10073                          335.8\n",
       "2    3              7152                          238.4\n",
       "3    4             14635                          487.8\n",
       "4    5              7916                          263.9\n",
       "5    6             17046                          511.4\n",
       "6    7              5636                          169.1\n",
       "7    8              2568                           85.6\n",
       "8    9              9522                          317.4\n",
       "9   10              7086                          236.2\n",
       "10  11              4832                          161.1\n",
       "11  12              6799                          226.6\n",
       "12  13              6328                          210.9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read negative cases description file\n",
    "with open(NEGATIVE_CASES_DESCRIPTION, 'r') as f:\n",
    "    negative_cases_desc = pd.read_csv(f, sep='\\t', header=0, thousands=',')\n",
    "\n",
    "negative_cases_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative frames (with no polyp in them) have `\"Negative\"` as part of their filename. We will use this information to filter them out from positive frames. Also, as seen in the above table, we only have negative frames for the first 13 cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>ID</th>\n",
       "      <th>Frame_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case_M_20181109094641_0U62372110931241_1_003_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case_M_20181109094641_0U62372110931241_1_003_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case_M_20181109094641_0U62372110931241_1_003_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case_M_20181109094641_0U62372110931241_1_003_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case_M_20181109094641_0U62372110931241_1_003_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109549</th>\n",
       "      <td>case_M_20181211095338_0U62372121159337_1_008_0...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109550</th>\n",
       "      <td>case_M_20181211095338_0U62372121159337_1_008_0...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109551</th>\n",
       "      <td>case_M_20181211095338_0U62372121159337_1_008_0...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109552</th>\n",
       "      <td>case_M_20181211095338_0U62372121159337_1_008_0...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109553</th>\n",
       "      <td>case_M_20181211095338_0U62372121159337_1_008_0...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109554 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Filename  ID  Frame_Class\n",
       "0       case_M_20181109094641_0U62372110931241_1_003_0...   1            1\n",
       "1       case_M_20181109094641_0U62372110931241_1_003_0...   1            1\n",
       "2       case_M_20181109094641_0U62372110931241_1_003_0...   1            1\n",
       "3       case_M_20181109094641_0U62372110931241_1_003_0...   1            1\n",
       "4       case_M_20181109094641_0U62372110931241_1_003_0...   1            1\n",
       "...                                                   ...  ..          ...\n",
       "109549  case_M_20181211095338_0U62372121159337_1_008_0...  13            1\n",
       "109550  case_M_20181211095338_0U62372121159337_1_008_0...  13            1\n",
       "109551  case_M_20181211095338_0U62372121159337_1_008_0...  13            1\n",
       "109552  case_M_20181211095338_0U62372121159337_1_008_0...  13            1\n",
       "109553  case_M_20181211095338_0U62372121159337_1_008_0...  13            1\n",
       "\n",
       "[109554 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_cases = defaultdict(list)\n",
    "# Retrieve negative images paths and cases\n",
    "negative_cases = {case_id: [image_path for image_path in glob.iglob('*.jpg', root_dir=os.path.join(RAW_DIR, f'case{case_id}')) if 'Negative' in image_path] for case_id in negative_cases_desc['ID']}\n",
    "\n",
    "# Drop cases with no negative frames\n",
    "negative_cases = {case_id: pd.DataFrame({'Filename': images, 'ID': case_id, 'Frame_Class': 1}) for case_id, images in negative_cases.items()} # Frame_Class = 1 means no polyp\n",
    "\n",
    "# Concatenate everything in a single pd.DataFrame\n",
    "negative_annotations = pd.concat([case for case in negative_cases.values()]).reset_index(drop=True)\n",
    "\n",
    "negative_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Frame_Class</th>\n",
       "      <th>XYXY</th>\n",
       "      <th>ID</th>\n",
       "      <th>XYWH</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Size</th>\n",
       "      <th>Location</th>\n",
       "      <th>Pathological_Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[408, 545, 568, 722]</td>\n",
       "      <td>1</td>\n",
       "      <td>[488.0, 633.5, 160.0, 177.0]</td>\n",
       "      <td>Is</td>\n",
       "      <td>6mm</td>\n",
       "      <td>C</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[388, 549, 561, 729]</td>\n",
       "      <td>1</td>\n",
       "      <td>[474.5, 639.0, 173.0, 180.0]</td>\n",
       "      <td>Is</td>\n",
       "      <td>6mm</td>\n",
       "      <td>C</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[390, 552, 561, 726]</td>\n",
       "      <td>1</td>\n",
       "      <td>[475.5, 639.0, 171.0, 174.0]</td>\n",
       "      <td>Is</td>\n",
       "      <td>6mm</td>\n",
       "      <td>C</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[390, 552, 561, 730]</td>\n",
       "      <td>1</td>\n",
       "      <td>[475.5, 641.0, 171.0, 178.0]</td>\n",
       "      <td>Is</td>\n",
       "      <td>6mm</td>\n",
       "      <td>C</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case_M_20181001100941_0U62372100109341_1_005_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>[389, 558, 557, 748]</td>\n",
       "      <td>1</td>\n",
       "      <td>[473.0, 653.0, 168.0, 190.0]</td>\n",
       "      <td>Is</td>\n",
       "      <td>6mm</td>\n",
       "      <td>C</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158685</th>\n",
       "      <td>case_M_20181211095338_0U62372121159337_1_008_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>13</td>\n",
       "      <td>[]</td>\n",
       "      <td>Is</td>\n",
       "      <td>5mm</td>\n",
       "      <td>T</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158686</th>\n",
       "      <td>case_M_20181211095338_0U62372121159337_1_008_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>13</td>\n",
       "      <td>[]</td>\n",
       "      <td>Is</td>\n",
       "      <td>5mm</td>\n",
       "      <td>T</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158687</th>\n",
       "      <td>case_M_20181211095338_0U62372121159337_1_008_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>13</td>\n",
       "      <td>[]</td>\n",
       "      <td>Is</td>\n",
       "      <td>5mm</td>\n",
       "      <td>T</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158688</th>\n",
       "      <td>case_M_20181211095338_0U62372121159337_1_008_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>13</td>\n",
       "      <td>[]</td>\n",
       "      <td>Is</td>\n",
       "      <td>5mm</td>\n",
       "      <td>T</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158689</th>\n",
       "      <td>case_M_20181211095338_0U62372121159337_1_008_0...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>13</td>\n",
       "      <td>[]</td>\n",
       "      <td>Is</td>\n",
       "      <td>5mm</td>\n",
       "      <td>T</td>\n",
       "      <td>Low-grade adenoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158690 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Filename  Frame_Class  \\\n",
       "0       case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "1       case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "2       case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "3       case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "4       case_M_20181001100941_0U62372100109341_1_005_0...            0   \n",
       "...                                                   ...          ...   \n",
       "158685  case_M_20181211095338_0U62372121159337_1_008_0...            1   \n",
       "158686  case_M_20181211095338_0U62372121159337_1_008_0...            1   \n",
       "158687  case_M_20181211095338_0U62372121159337_1_008_0...            1   \n",
       "158688  case_M_20181211095338_0U62372121159337_1_008_0...            1   \n",
       "158689  case_M_20181211095338_0U62372121159337_1_008_0...            1   \n",
       "\n",
       "                        XYXY  ID                          XYWH Shape Size  \\\n",
       "0       [408, 545, 568, 722]   1  [488.0, 633.5, 160.0, 177.0]    Is  6mm   \n",
       "1       [388, 549, 561, 729]   1  [474.5, 639.0, 173.0, 180.0]    Is  6mm   \n",
       "2       [390, 552, 561, 726]   1  [475.5, 639.0, 171.0, 174.0]    Is  6mm   \n",
       "3       [390, 552, 561, 730]   1  [475.5, 641.0, 171.0, 178.0]    Is  6mm   \n",
       "4       [389, 558, 557, 748]   1  [473.0, 653.0, 168.0, 190.0]    Is  6mm   \n",
       "...                      ...  ..                           ...   ...  ...   \n",
       "158685                    []  13                            []    Is  5mm   \n",
       "158686                    []  13                            []    Is  5mm   \n",
       "158687                    []  13                            []    Is  5mm   \n",
       "158688                    []  13                            []    Is  5mm   \n",
       "158689                    []  13                            []    Is  5mm   \n",
       "\n",
       "       Location Pathological_Diagnosis  \n",
       "0             C      Low-grade adenoma  \n",
       "1             C      Low-grade adenoma  \n",
       "2             C      Low-grade adenoma  \n",
       "3             C      Low-grade adenoma  \n",
       "4             C      Low-grade adenoma  \n",
       "...         ...                    ...  \n",
       "158685        T      Low-grade adenoma  \n",
       "158686        T      Low-grade adenoma  \n",
       "158687        T      Low-grade adenoma  \n",
       "158688        T      Low-grade adenoma  \n",
       "158689        T      Low-grade adenoma  \n",
       "\n",
       "[158690 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with the annotations dataframe from earlier\n",
    "annotations = positive_annotations.merge(negative_annotations, on=['ID', 'Filename', 'Frame_Class'], how='outer')\n",
    "\n",
    "# Clean-up\n",
    "annotations['XYXY'] = annotations['XYXY'].fillna(\"\").apply(list) # Use empty lists instead of NaNs\n",
    "annotations['XYWH'] = annotations['XYWH'].fillna(\"\").apply(list) # Use empty lists instead of NaNs\n",
    "annotations = annotations.groupby('ID').apply(lambda x: x.ffill().bfill()) # Fill information for negative frames with same from positive frames (they belong to the same case)\n",
    "\n",
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above DataFrame contains all the information regarding the SUN Dataset: bounding box annotations (including polyp pathological diagnoses) for positive frames and negative frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save separate annotation files for each frame in `03_primary/labels`.\n",
    "\n",
    "The `03_primary` folder will be our main source of data from which we will sample out our training and validation sets to `04_model_input` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"labels\" dir if needed\n",
    "LABELS_DIR = os.path.join(PRIMARY_DIR, 'labels')\n",
    "LABELS_EXT = '.json'\n",
    "\n",
    "if not os.path.exists(LABELS_DIR):\n",
    "    os.mkdir(LABELS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the custom annotation template we will be using for the SUN Dataset labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': '',\n",
       " 'class': 0,\n",
       " 'labels': [{'label_id': 0,\n",
       "   'category_id': 0,\n",
       "   'category_name': '',\n",
       "   'segmentation': [],\n",
       "   'bbox': []}],\n",
       " 'other': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load \"annotation_template.json\"\n",
    "with open(ANNOTATION_TEMPLATE, 'r') as f:\n",
    "    annotation_template = json.load(f)\n",
    "\n",
    "annotation_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each image, we will have an homonimous label `.json` file which will contain the following information:\n",
    "* `image_id`: name of the image.\n",
    "* `class`: either `0` or `1`, indicating a positive/polyp (`0`) or negative/non-polyp (`1`) frame.\n",
    "* `labels`: if `class=0`, then `labels` contains the ground-truth annotations for that frame. Annotations will include a unique identifier of the label(`label_id`), the ID of the pathological diagnosis (`category_id`. See `polyp_classes.json`), the segmentation mask polygonal coordinates - if any (`segmentation`), and the bounding box coordinates (`bbox`).\n",
    "* `other`: any other additional note, comment, information regarding the particular image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now also load the pathological diagnosis classes present in the SUN Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polyp_classes': [{'id': 1,\n",
       "   'name': 'Hyperplastic polyp',\n",
       "   'color': '(255,255,155,50)',\n",
       "   'outline': '(255,222,0)'},\n",
       "  {'id': 2,\n",
       "   'name': 'Sessile serrated lesion',\n",
       "   'color': '(255,102,102,50)',\n",
       "   'outline': '(255,60,60)'},\n",
       "  {'id': 3,\n",
       "   'name': 'Low-grade adenoma',\n",
       "   'color': '(51,51,255,50)',\n",
       "   'outline': '(18,18,184)'},\n",
       "  {'id': 4,\n",
       "   'name': 'Traditional serrated adenoma',\n",
       "   'color': '(0,200,10,50)',\n",
       "   'outline': '(0,120,10)'},\n",
       "  {'id': 5,\n",
       "   'name': 'High-grade adenoma',\n",
       "   'color': '(255,40,40,50)',\n",
       "   'outline': '(160,0,0)'},\n",
       "  {'id': 6,\n",
       "   'name': 'Invasive carcinoma',\n",
       "   'color': '(188,0,255,50)',\n",
       "   'outline': '(140,0,190)'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load \"classes_template.json\"\n",
    "with open(POLYP_CLASSES, 'r') as f:\n",
    "    polyp_classes = json.load(f)\n",
    "\n",
    "polyp_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each polyp class, we assign a unique ID (`id`), the corresponding pathological diagnosis (`name`), and different colors for visualization purposes (`color` and `outline`. `color` should be used for the segmentation masks \"inside\", as the color is semi-transparent. `outline` should be used for the contour of segmentation masks or the bounding box itself)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can populate each annotation template for each image using the information from each annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B.**: for the SUN Dataset we only have **one** bounding box annotation for each image. This might not be the case for images coming from other datasets or for possible future extensions of the SUN Dataset itself. As a matter of fact, there may be multiple objects detected in the same frame (be them other polyps or other objects of interests - such as image artefacts, etc.). \n",
    "\n",
    "Also, there might be multiple annotations associated with the same frame (bounding boxes, segmentation masks, etc.), therefore we keep our `labels` field as a **list of labels** (even though for the SUN Dataset we will only have one).\n",
    "\n",
    "This might come in handy in the future when extending the framework to other datasets or for more refined annotations for the SUN Dataset itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating and saving each image's annotations...: 100%|██████████| 158690/158690 [00:10<00:00, 14560.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Store all annotations in a single file for tidyness\n",
    "all_annotations = {'annotations': []}\n",
    "\n",
    "# Populate annotation template for each image\n",
    "# NB itertuples() returns a namedtuple for each row, whose fields/columns can be accessed as class attributes (via \"somenamedtuple.<fieldname>\")\n",
    "for image_row in tqdm.tqdm(annotations.itertuples(), desc=\"Populating and saving each image's annotations...\", total=len(annotations)):\n",
    "    # Copy template structure\n",
    "    image_annot = annotation_template\n",
    "    image_annot['labels'] = [] # Initialise empty\n",
    "    image_annot['other'] = []\n",
    "\n",
    "    # Populate\n",
    "    # Add image name and class\n",
    "    image_annot['image_id'] = image_row.Filename\n",
    "    image_annot['class'] = image_row.Frame_Class\n",
    "\n",
    "    # Add annotations\n",
    "    if image_row.Frame_Class == 0: # NB: Frame_Class=0 means POSITIVE (polyp) frame\n",
    "        # Extract polyp class ID\n",
    "        polyp_class = [polyp['id'] for polyp in polyp_classes['polyp_classes'] if polyp['name']==image_row.Pathological_Diagnosis]\n",
    "        \n",
    "        image_annot['labels'] = [\n",
    "            {\n",
    "                'label_id': image_row.Index+1, # Unique, sequential label ID\n",
    "                'category_id': polyp_class[0], # Polyp ID from classes_template.json\n",
    "                'category_name': image_row.Pathological_Diagnosis,\n",
    "                'xyxy': image_row.XYXY,\n",
    "                'xywh': image_row.XYWH\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    # Add other useful information\n",
    "    image_annot['other'] = [\n",
    "        {\n",
    "            'LabelID': image_row.Index+1,\n",
    "            'CaseID': image_row.ID,\n",
    "            'Polyp Shape': image_row.Shape,\n",
    "            'Polyp Size': image_row.Size,\n",
    "            'Polyp Location': image_row.Location\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    all_annotations['annotations'].append(image_annot)\n",
    "\n",
    "\n",
    "################################### RUN ONLY ONCE OR IF NEEDED ###################################\n",
    "# # Save annotation file as \"filename.json\" in \"03_primary/labels\"\n",
    "#     with open(os.path.join(LABELS_DIR, image_row.Filename[:-4]+LABELS_EXT), 'w') as f:\n",
    "#         json.dump(image_annot, f)\n",
    "\n",
    "\n",
    "# # Save annotations in a single json file located in \"03_primary/labels.json\"\n",
    "# with open(os.path.join(PRIMARY_DIR, 'labels.json'), 'w') as f:\n",
    "#     json.dump(all_annotations, f)\n",
    "\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Move all images to `03_primary/images` folder.\n",
    "\n",
    "Finally, we copy all of the images (both positive AND negative frames) to the above-mentioned folder, from which we will sample out the training/validation sets (just like for the labels). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = os.path.join(PRIMARY_DIR, 'images')\n",
    "\n",
    "# Make sure the folder exists\n",
    "if not os.path.exists(IMAGES_DIR):\n",
    "    os.mkdir(IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images from raw to primary folder...: 100%|██████████| 158690/158690 [00:41<00:00, 3857.72it/s]\n"
     ]
    }
   ],
   "source": [
    "################################### RUN ONLY ONCE OR IF NEEDED ###################################\n",
    "# # Copy images to selected folder\n",
    "# for image_path in tqdm.tqdm(glob.iglob(os.path.join(RAW_DIR, 'case*/*.jpg')), desc='Copying images from raw to primary folder...', total=len(annotations)):\n",
    "#     # Get the image name only\n",
    "#     image_name = os.path.basename(image_path)\n",
    "\n",
    "#     # Copy image\n",
    "#     shutil.copyfile(image_path, os.path.join(IMAGES_DIR, image_name))\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Split and save training and validation sets in `04_model_input/train` and in `04_model_input/val`.\n",
    "\n",
    "For storage issues purposes, we will use `os.symlink` to just create shortcuts to the files in the `03_primary` folder. \n",
    "\n",
    "First, we need to set the **RNG seed** for reproducible results. `np.random.seed()` is not the recommended way to fix the seed anymore. Instead, we use `np.random.default_rng()`. See the [documentation](https://numpy.org/doc/stable/reference/random/generator.html?highlight=default_rng#) and [this blogpost](https://towardsdatascience.com/stop-using-numpy-random-seed-581a9972805f) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix seed for reproducibility\n",
    "SEED = 42\n",
    "RNG = np.random.default_rng(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only split into training and validation sets to exploit the SUN Dataset the most. For testing purposes, we can use any of the publicly available colonoscopy datasets - which would also provide generalizabity tests for our models.\n",
    "\n",
    "We perform train/val split on a 80/20 and **per-class** basis. \n",
    "\n",
    "A list of public datasets for automatic polyp detection can be found [here](https://github.com/sing-group/deep-learning-colonoscopy#public-datasets).\n",
    "\n",
    "Also, we will not include all negative frames in our dataset, but only some of them (as detailed in [_Misawa et al._](https://www.giejournal.org/article/S0016-5107(20)34655-1/fulltext)). However, we will use the number of negative frames as a hyperparameter and evaluate our models against varying number of negative samples (therefore, we will implement a method in our dataset to only take `N` negative frames).\n",
    "\n",
    "For now, we include all of them in the training and validation sets (but we make sure to include an even split of positive and negative frames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---POSITIVE FRAMES---\n",
      "Trainset: 39306 | Valset: 9830 | Total: 49136\n",
      "---NEGATIVE FRAMES---\n",
      "Trainset: 87643 | Valset: 21911 | Total: 109554\n"
     ]
    }
   ],
   "source": [
    "# Get negative frames list\n",
    "negative_list = negative_annotations['Filename'].to_list()\n",
    "\n",
    "# Shuffle it (in-place)\n",
    "RNG.shuffle(negative_list)\n",
    "\n",
    "# Get training and validation split indices\n",
    "SPLIT = 0.8\n",
    "NEG_SPLIT = int(SPLIT * len(negative_list))\n",
    "\n",
    "# For each positive annotation, get each polyp class filelist (shuffled) and the split\n",
    "classes_list = {}\n",
    "classes_split = {}\n",
    "\n",
    "for polyp in polyp_classes['polyp_classes']:\n",
    "    classes_list[polyp['name']] = positive_annotations.loc[positive_annotations['Pathological_Diagnosis']==polyp['name'], 'Filename'].to_list()\n",
    "    RNG.shuffle(classes_list[polyp['name']]) # shuffle in place\n",
    "    # Get split indices\n",
    "    classes_split[polyp['name']] = int(SPLIT * len(classes_list[polyp['name']]))\n",
    "\n",
    "# Save neatly in a dict\n",
    "dataset = {}\n",
    "\n",
    "dataset['train'] = {}\n",
    "dataset['val'] = {}\n",
    "\n",
    "# Positive train/val split\n",
    "train_positive = [polyp_list[:split] for polyp_list, split in zip(classes_list.values(), classes_split.values())] # list of lists\n",
    "val_positive = [polyp_list[split:] for polyp_list, split in zip(classes_list.values(), classes_split.values())] # list of lists\n",
    "# Unpack\n",
    "train_positive = [fname for sublist in train_positive for fname in sublist]\n",
    "val_positive = [fname for sublist in val_positive for fname in sublist]\n",
    "\n",
    "# Extract positive images and labels\n",
    "dataset['train']['positive'] = {\n",
    "    'images': train_positive,\n",
    "    'labels': [fname[:-4]+LABELS_EXT for fname in train_positive]\n",
    "}\n",
    "dataset['val']['positive'] = {\n",
    "    'images': val_positive,\n",
    "    'labels': [fname[:-4]+LABELS_EXT for fname in val_positive]\n",
    "}\n",
    "\n",
    "# Negative train/val split\n",
    "train_negative = negative_list[:NEG_SPLIT]\n",
    "val_negative = negative_list[NEG_SPLIT:]\n",
    "\n",
    "# Extract negative images and labels\n",
    "dataset['train']['negative'] = {\n",
    "    'images': train_negative,\n",
    "    'labels': [fname[:-4]+LABELS_EXT for fname in train_negative]\n",
    "}\n",
    "dataset['val']['negative'] = {\n",
    "    'images': val_negative,\n",
    "    'labels': [fname[:-4]+LABELS_EXT for fname in val_negative]\n",
    "}\n",
    "\n",
    "# Sanity check\n",
    "print('---POSITIVE FRAMES---')\n",
    "print(f\"Trainset: {len(dataset['train']['positive']['images'])} | Valset: {len(dataset['val']['positive']['images'])} | Total: {len(dataset['train']['positive']['images']) + len(dataset['val']['positive']['images'])}\")\n",
    "\n",
    "print('---NEGATIVE FRAMES---')\n",
    "print(f\"Trainset: {len(dataset['train']['negative']['images'])} | Valset: {len(dataset['val']['negative']['images'])} | Total: {len(dataset['train']['negative']['images']) + len(dataset['val']['negative']['images'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASPLITS = ['train', 'val']\n",
    "FRAME_TYPES = ['positive', 'negative']\n",
    "XY = ['images', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train folder.\n",
      "Created train/images folder.\n",
      "Created train/labels folder.\n",
      "Created val folder.\n",
      "Created val/images folder.\n",
      "Created val/labels folder.\n"
     ]
    }
   ],
   "source": [
    "# Create folders\n",
    "for datasplit in DATASPLITS:\n",
    "    INPUT_DIR = os.path.join(MODEL_INPUT_DIR, datasplit)\n",
    "    # Check if \"train\" or \"val\" folders already exist\n",
    "    if not os.path.exists(INPUT_DIR):\n",
    "        print(f'Created {datasplit} folder.')\n",
    "        os.mkdir(INPUT_DIR)\n",
    "    \n",
    "    # Create also images and labels folders\n",
    "    for xy in XY:\n",
    "        XY_DIR = os.path.join(INPUT_DIR, xy)\n",
    "        # Check if \"images\" or \"labels\" folders already exist\n",
    "        if not os.path.exists(XY_DIR):\n",
    "            print(f'Created {datasplit}/{xy} folder.')\n",
    "            os.mkdir(XY_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating symlinks for train set for positive images...: 100%|██████████| 39306/39306 [00:00<00:00, 71544.48it/s]\n",
      "Creating symlinks for train set for positive labels...: 100%|██████████| 39306/39306 [00:00<00:00, 68438.42it/s]\n",
      "Creating symlinks for train set for negative images...: 100%|██████████| 87643/87643 [00:01<00:00, 66432.20it/s]\n",
      "Creating symlinks for train set for negative labels...: 100%|██████████| 87643/87643 [00:01<00:00, 65353.66it/s]\n",
      "Creating symlinks for val set for positive images...: 100%|██████████| 9830/9830 [00:00<00:00, 76079.67it/s]\n",
      "Creating symlinks for val set for positive labels...: 100%|██████████| 9830/9830 [00:00<00:00, 74508.20it/s]\n",
      "Creating symlinks for val set for negative images...: 100%|██████████| 21911/21911 [00:00<00:00, 74269.70it/s]\n",
      "Creating symlinks for val set for negative labels...: 100%|██████████| 21911/21911 [00:00<00:00, 71345.48it/s]\n"
     ]
    }
   ],
   "source": [
    "################################### RUN ONLY ONCE OR IF NEEDED ###################################\n",
    "# # Create symlink of the corresponding image and label in \"04_model_input/*/images\" and \"04_model_input/*/labels\"\n",
    "# for datasplit in DATASPLITS:\n",
    "#     for frame_type in FRAME_TYPES:\n",
    "#         for xy in XY:\n",
    "#             # Pair filepaths in a dict {src: dst}\n",
    "#             filepairs = {os.path.join(PRIMARY_DIR, xy, fname): os.path.join(MODEL_INPUT_DIR, datasplit, xy, fname) for fname in dataset[datasplit][frame_type][xy]}\n",
    "\n",
    "#             for src, dst in tqdm.tqdm(filepairs.items(), desc=f'Creating symlinks for {datasplit} set for {frame_type} {xy}...', total=len(dataset[datasplit][frame_type][xy])):\n",
    "#                 os.symlink(src, dst)\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "for datasplit in DATASPLITS:\n",
    "    x = [img[:-4] for img in os.listdir(os.path.join(MODEL_INPUT_DIR, datasplit, 'images'))]\n",
    "    y = [lbl[:-5] for lbl in os.listdir(os.path.join(MODEL_INPUT_DIR, datasplit, 'labels'))]\n",
    "\n",
    "    assert sorted(x) == sorted(y), f'There are some mismatches or missing files between images and labels for the {datasplit} set.'   "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82f8bbdca075e735cd7b5ecdbbc79d17d3ada3017f7b6c600a315b401a494d2b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ms-thesis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
